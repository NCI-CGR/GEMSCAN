#!/usr/bin/env python3
# Authors: Shalabh Suman, Bari Ballew, Wendy Wong

import os
import subprocess
from glob import glob

"""DeepVariant module of CGR germline variant calling pipeline
"""


if clusterMode == "gcp" or useRemoteFiles:
    from snakemake.remote.GS import RemoteProvider as GSRemoteProvider
    GS = GSRemoteProvider()


rule DV_concatVariantsByChrom:
    """Concatenating GLnexus merged bcf into single joined genotyped bcf,
    when the by_chrom option is used
    """
    input:
        vcf=expand(outputDir +  "deepVariant/genotyped/DV_variants_{chrom}.bcf", chrom=chromList),
        idx=expand(outputDir +  "deepVariant/genotyped/DV_variants_{chrom}.bcf.csi", chrom=chromList),
    output:
        temp(outputDir +  "deepVariant/genotyped/DV_variants.bcf"),
    benchmark:
        outputDir +  "run_times/DV_concatVariantsByChrom/concatVariantsByChrom.tsv"
    conda:
        "../envs/environment.yaml"
    singularity:
        "docker://quay.io/shukwong/bcftools:2020-12-09"
    shell:
        "bcftools concat -Ou -a {input.vcf} > {output}"


rule DV_indexBCFByChrom:
    input:
        bcf=outputDir +  "deepVariant/genotyped/DV_variants_{chrom}.bcf",
    output:
        idx=outputDir +  "deepVariant/genotyped/DV_variants_{chrom}.bcf.csi",
    benchmark:
        outputDir +  "run_times/DV_indexBCFByChrom/{chrom}.tsv"
    conda:
        "../envs/environment.yaml"
    singularity:
        "docker://quay.io/shukwong/bcftools:2020-12-09"
    shell:
        "bcftools index {input.bcf}"


rule DV_concat_vcfs:
    """Concatenate vcfs
    """
    input:
        vcf=expand(outputDir +  "deepVariant/called/{chrom}/{{sample}}.vcf.gz", chrom=chromList),
        idx=expand(outputDir +  "deepVariant/called/{chrom}/{{sample}}.vcf.gz.tbi", chrom=chromList),
    output:
        gz=outputDir + "deepVariant/called/vcfs/{sample}_all_chroms.vcf.gz",
    params:
        temp(directory(outputDir + "DV_concat_vcfs/{sample}/")),
    benchmark:
        outputDir +  "run_times/DV_concat_vcfs/{sample}.tsv"
    conda:
        "../envs/environment.yaml"
    singularity:
        "docker://quay.io/shukwong/bcftools:2020-12-09"
    shell:
        "mkdir -p {params}; bcftools concat -Ou -a {input.vcf} | bcftools sort -T {params} -Oz -o {output.gz}" # sort -k1,1 -k2,2n > {output}'


rule DV_create_each_sample_manifest:
    """Create list of files for GLnexus to merge
    Needed to break up into two steps (individual manifest,
    then merging to cohort manifest) to work around command
    line character limits when run at scale.
    """
    input:
        outputDir +  "deepVariant/called/{chrom}/{sample}.g.vcf.gz" if by_chrom else outputDir +  "deepVariant/called_by_sample/{sample}.g.vcf.gz",
    output:
        temp(outputDir +  "deepVariant/called/manifests/{chrom}/{sample}_manifest.txt") if by_chrom else temp(
            outputDir +  "deepVariant/called/gvcfs/{sample}_manifest.txt"
        ),
    resources:
        machine_type="n1-standard-2"     
    benchmark:
        outputDir +  "run_times/DV_create_each_sample_manifest/{chrom}/{sample}_manifest.tsv" if by_chrom else outputDir +  "run_times/DV_create_sample_manifest/{sample}_manifest.tsv"
    shell:
        "echo {input} > {output}"


rule DV_create_cohort_manifest:
    input:
        # expand(
            # outputDir +  "deepVariant/called/manifests/{{chrom}}/{sample}_manifest.txt", sample=sampleList
        # ) if by_chrom else expand(
            # outputDir +  "deepVariant/called/gvcfs/{sample}_manifest.txt", sample=sampleList
        # ),
        expand(
            outputDir +  "deepVariant/called/{{chrom}}/{sample}.g.vcf.gz", sample=sampleList, chrom=chromList
        ) if by_chrom else expand(
            outputDir +  "deepVariant/called_by_sample/{sample}.g.vcf.gz", sample=sampleList, chrom=chromList
        ),        
    output:
        outputDir +  "deepVariant/called/gvcfs/{chrom}/manifest.txt" if by_chrom else outputDir +  "deepVariant/called/gvcfs/manifest.txt",
    benchmark:
        outputDir +  "run_times/DV_create_cohort_manifest/{chrom}_manifest.tsv" if by_chrom else outputDir +  "run_times/DV_create_cohort_manifest/manifest.tsv"
    # params:
        # manDir=(
            # outputDir + "deepVariant/called/manifests/{chrom}/"
            # if by_chrom
            # else outputDir + "deepVariant/called/gvcfs/"
        # ),
    run:
        if by_chrom:
            for manDir in output:
                chr = os.path.basename(os.path.dirname(manDir))
                with open(os.path.dirname(manDir) + '/manifest.txt', 'w') as outfile:
                    inDir = os.path.dirname(manDir).strip('gvcfs/')
                    print(inDir)
                    #for item in (glob('/' + inDir + wildcards.sample + '.g.vcf.gz')):     
                    for item in input:                        
                        outfile.write("%s\n" % item)                       
        else:
            with open(output[0], 'w') as outfile: 
                for item in input:
                    outfile.write("%s\n" % item)
        

rule DV_GLmerge_gvcfs:
    """Merge gvcfs into one multi-sample vcf

    "The glnexus_cli executable consumes the gVCF files, and a three-column
    BED file giving the genomic ranges to analyze. For exomes, the BED file
    might contain the exome capture targets with some padding, while for
    WGS you can just give the full-length chromosomes."

    Are shards are equivalent regions across samples?  Probably not?
    Then can't parallelize by shard here.  Do we need parallelization?
    If so, should we first split by region?

    GLnexus outputs uncompressed bcf.

    GLnexus creates a directory called "GLnexus.DB" in the working directory.  Track?
    If this step fails, then the database GLnexus.DB already exists, and resuming
    the pipeline will result in an error.  Add a timestamp?

    Now that we have Strelka as well we can't have the "GLnexus.DB" in the working directory.
    Changing the working directory in the command line (and borrowing dt from HaplotypeCaller)

    """
    input:
        l=(
            expand(outputDir +  "deepVariant/called/{{chrom}}/{sample}.g.vcf.gz", sample=sampleList)
            if by_chrom
            else expand(outputDir +  "deepVariant/called_by_sample/{sample}.g.vcf.gz", sample=sampleList)
        ),
        m=(
            outputDir +  "deepVariant/called/gvcfs/{chrom}/manifest.txt"
            if by_chrom
            else outputDir +  "deepVariant/called/gvcfs/manifest.txt"
        ),
        b="split_regions/{chrom}.bed" if by_chrom else bedFile,
    output:
        outputDir +  "deepVariant/genotyped/DV_variants_{chrom}.bcf" if by_chrom else temp(
            outputDir +  "deepVariant/genotyped/DV_variants.bcf"
        ),
    params:
        workDir=outputDir + "DV_GLmerge_gvcfs/" + "{chrom}/" if by_chrom else outputDir + "DV_GLmerge_gvcfs/all_chrs",
        config=glnexus_dv_config,
        memGB=glnexus_memGB
    resources:
        machine_type="n1-standard-8",
        #runtime=2880,
        mem_mb=glnexus_memGB*1000 
    threads: 8     
    benchmark:
        outputDir +  "run_times/DV_GLmerge_gvcfs/{chrom}/DV_GLmerge_gvcfs.tsv" if by_chrom else outputDir +  "run_times/DV_GLmerge_gvcfs/DV_GLmerge_gvcfs.tsv"
    conda:
        "../envs/environment.yaml"
    singularity:
        "docker://quay.io/shukwong/bcftools:2020-12-09"
    shell:
        "[ -d {params.workDir} ] && rm -rf {params.workDir}; mkdir -p {params.workDir};"
        "if [ ! -f {params.workDir}/glnexus_cli ]; then wget https://github.com/dnanexus-rnd/GLnexus/releases/download/v1.2.7/glnexus_cli -P {params.workDir}; chmod +x {params.workDir}/glnexus_cli; fi;"
        "{params.workDir}/glnexus_cli --config DeepVariant --dir {params.workDir}/GLnexus.DB  --bed {input.b} --list {input.m} -m {params.memGB} -t {threads} > {output};"
        "rm {params.workDir}/glnexus_cli;"


rule DV_compress_merged_vcfs:
    """
    Ading --min-ac 1 here so that no calls after GLnexus merge are not in the final output
    """
    input:
        outputDir +  "deepVariant/genotyped/DV_variants.bcf",
    output:
        gz=protected(outputDir +  "deepVariant/genotyped/DV_variants.vcf.gz"),
        tbi=protected(outputDir +  "deepVariant/genotyped/DV_variants.vcf.gz.tbi"),
    benchmark:
        outputDir +  "run_times/DV_compress_merged_vcfs/DV_variants.tsv"
    conda:
        "../envs/environment.yaml"
    singularity:
        "docker://quay.io/shukwong/bcftools:2020-12-09"
    shell:
        "bcftools view --min-ac 1 {input} | bgzip -c > {output.gz}; tabix -p vcf {output.gz}"


rule DV_run_deepvariant:
    input:
        ref=path_sanitize(refGenome),
        ref_index=path_sanitize(refGenome + ".fai"),
        bam=lambda wc: path_sanitize(sample2bam[wc.sample]),
        bai=lambda wc: path_sanitize(sample2bamIndex[wc.sample]),
        bed="split_regions/{chrom}.bed" if by_chrom else bedFile,
    output:
        vcf=(
            outputDir +  "deepVariant/called/{chrom}/{sample}.vcf.gz"
            if by_chrom
            else outputDir +  "deepVariant/called_by_sample/{sample}.vcf.gz"
        ),
        vcf_tbi=(
            outputDir +  "deepVariant/called/{chrom}/{sample}.vcf.gz.tbi"
            if by_chrom
            else outputDir +  "deepVariant/called_by_sample/{sample}.vcf.gz.tbi"
        ),
        gvcf=(
            outputDir +  "deepVariant/called/{chrom}/{sample}.g.vcf.gz"
            if by_chrom
            else outputDir +  "deepVariant/called_by_sample/{sample}.g.vcf.gz"
        ),
        gvcf_tbi=(
            outputDir +  "deepVariant/called/{chrom}/{sample}.g.vcf.gz.tbi"
            if by_chrom
            else outputDir +  "deepVariant/called_by_sample/{sample}.g.vcf.gz.tbi"
        ),
    params:
        model_type=model_type,
        sm=lambda wc: sample2sm[wc.sample],
        threads=threads,
        split_inputs=" ".join(str(x) for x in range(0, int(threads))),
        tmp_dir="DV_run_deepvariant_TMP",
        log_dir=outputDir + "/logs",
        #model_dir=get_DV_model_path(model_type)
    resources:
        machine_type="n1-standard-8",
        #runtime=2880,
        mem_mb=dv_memGB*1000
    threads: 8
    benchmark:
        outputDir +  "run_times/DV_run_deepvariant/{chrom}/{sample}.tsv" if by_chrom else outputDir +  "run_times/DV_run_deepvariant/{sample}.tsv"
    conda:
        "../envs/deepvariant.yaml"
    singularity:
        "docker://google/deepvariant:1.0.0"
    log:
        "logs/DV_run_deepvariant/DV_run_deepvariant.{chrom}.{sample}.log" if by_chrom else "logs/DV_run_deepvariant/DV_run_deepvariant.{sample}.log",
    shell:
        "if [ -f /opt/deepvariant/bin/run_deepvariant ]; then \
        /opt/deepvariant/bin/run_deepvariant \
                                --model_type={params.model_type} \
                                --ref={input.ref}  \
                                --reads={input.bam} \
                                --regions {input.bed} \
                                --sample_name {params.sm} \
                                --output_vcf={output.vcf} \
                                --output_gvcf={output.gvcf} \
                                --num_shards={params.threads}; \
        else \
        rm -rf {params.tmp_dir}; mkdir -p {params.tmp_dir}; \
        dv_make_examples.py \
                --cores {threads} \
                --ref {input.ref} \
                --reads {input.bam} \
                --sample {params.sm} \
                --examples {params.tmp_dir}/{params.sm} \
                --gvcf {params.tmp_dir}/{params.sm}.gvcf.tmp \
                --logdir {params.log_dir}; \
        dv_call_variants.py \
                --cores {threads} \
                --outfile {params.tmp_dir}/{params.sm}.tmp \
                --sample {params.sm} \
                --examples {params.tmp_dir}/{params.sm} \
                --model {params.model_type}; \
        dv_postprocess_variants.py \
                --ref {input.ref} \
                --infile {params.tmp_dir}/{params.sm}.tmp \
                --outfile {output.vcf} \
                --gvcf_infile {params.tmp_dir}/{params.sm}.gvcf.tmp \
                --gvcf_outfile {output.gvcf}; \
        fi"

